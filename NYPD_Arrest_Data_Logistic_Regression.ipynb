{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed17dc48",
   "metadata": {},
   "source": [
    "# Intro to Machine Learning\n",
    "## Logistic Regression \n",
    "\n",
    "- Two types of data\n",
    "    - labeled data: used for Regression and classification\n",
    "    - use when data has a variable that you are trying to predict (predicting an outcome of a game)\n",
    "    <br> <br>\n",
    "    - un-labeled data: used for clustering\n",
    "    - use when data does not have a variable that it is trying to predict (AI trying to learn voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97b407",
   "metadata": {},
   "source": [
    "## ML algorithms fall into three main categories \n",
    "\n",
    "- Regressors: using labeled data, to predict numerical value\n",
    "    - ex: predicting value of a house on dollars <br> <br>\n",
    "    \n",
    "- Classifiers: using labeled data, predicts a discrete class label\n",
    "    - ex: predict of cancer or not, predicting what type of animal is in the image\n",
    "    <br> <br>\n",
    "- Clusterers: using unlabeled data, labels discrete clusters within a data set. Great when you aren't able to generate labels\n",
    "    - ex: identify what type of customers you have "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2713b106",
   "metadata": {},
   "source": [
    "## Logistic Regression- a classifier\n",
    "\n",
    "- Logistic Reggression (Logit): classification machine learning algorithm. Uses labeled data to predict a discrete outcome by assigning a predicted probability to each decision. \n",
    "    - LR separates the input into \"regions\" by a linear boundary\n",
    "    - sigmoid function is used to separate the data into two areas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f2df8",
   "metadata": {},
   "source": [
    "## Classification threshold\n",
    "\n",
    "- A threshold(linear boundary) is placed to determine whether the classification is a yes or no (above or below\n",
    "\n",
    "- for example weight. A threshold is place to determine obesity. If weight(data) is above the threshold, obese. if below the threshold, not obese. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5035b",
   "metadata": {},
   "source": [
    "## Wrong classifications\n",
    "\n",
    "- false postive: labeled as true when in reality, it is false\n",
    "    - ex: classifier is obese, but the truth that it is not obese\n",
    "<br> <br> \n",
    "\n",
    "- false negative: labeled as false, but in reality, it is true\n",
    "    - ex: labeled as not obese, but truth is obese\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca1e095",
   "metadata": {},
   "source": [
    "## Logistic Regression Pros and Cons\n",
    "- Pros: \n",
    "    - less prone to over-fitting compared to other classifiers\n",
    "    - computationally easy to train and predict values\n",
    "    - describes relationship between independent variables and dependent variables\n",
    "\n",
    "- Cons:\n",
    "    - main problem, the assumption of linearity between the dependent variable and the independent variables\n",
    "    - if more columns than rows (if number of observations are lesser than the number of features), LR should not be used, it may lead to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd7a62",
   "metadata": {},
   "source": [
    "## Evaluation Terms for classifiers: \n",
    "\n",
    "- True negative, True Postive, False negative, False postive\n",
    "<br> <br> \n",
    "- The first term (True or False) is if the prediction was correct or not. True means correct, false means incorrect\n",
    "<br> <br>\n",
    "\n",
    "- the second term (postive or negative) is what the classifier guessed. Did it say it yes or did it say no "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49f4b0",
   "metadata": {},
   "source": [
    "## Evaluation metrics for classifiers\n",
    "\n",
    "Meterics that tell us how our model is performing\n",
    "\n",
    "- The four metrics: Accuracy, Precision, Recall, F1 Score\n",
    "\n",
    "<br> \n",
    "\n",
    "- Accuracy: great starter. The count of all predictions you got correct divided by the total number of predictions (Percent of predictions we got correct) \n",
    "    - Accuracy = (TP + TN) / (TP + TN + FP + FN) \n",
    "    - Accuracy = # of correct predictions / all predictions\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Recall: true positive rate (sensitivity). How many times was the Yes called correctly. Pefect score is 1.0, as it goes down, the score goes down\n",
    "    - false negative is looked here. \n",
    "\n",
    "<br>\n",
    "\n",
    "- Precision: What proportion of positive idenifications was actualy correct? Out of all the times our model says \"Yes\", what percentage was it correct. \n",
    "    - perfect score is 1.0, a model produces no false positives has a precision of 1.0\n",
    "    - precision = TP/ (TP + FP) \n",
    "    \n",
    "- F1 score: harmonic mean of precision and recall. Good overall evaluation metric.\n",
    "    - F1 score a weighted average of the precision and recall. Best at 1, worst at 0\n",
    "    - F1 = 2 * (precision * recall) / (precision + recall) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7ddf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
